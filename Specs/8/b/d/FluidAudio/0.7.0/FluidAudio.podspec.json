{
  "name": "FluidAudio",
  "version": "0.7.0",
  "summary": "Speaker diarization, voice-activity-detection and transcription with CoreML",
  "description": "Fluid Audio is a Swift SDK for fully local, low-latency audio AI on Apple devices,\nwith inference offloaded to the Apple Neural Engine (ANE). The SDK includes\nstate-of-the-art speaker diarization, transcription, and voice activity detection\nvia open-source models that can be integrated with just a few lines of code.",
  "homepage": "https://github.com/FluidInference/FluidAudio",
  "license": {
    "type": "MIT",
    "file": "LICENSE"
  },
  "authors": {
    "FluidInference": "info@fluidinference.com"
  },
  "platforms": {
    "ios": "17.0",
    "osx": "14.0"
  },
  "source": {
    "git": "https://github.com/FluidInference/FluidAudio.git",
    "tag": "v0.7.0"
  },
  "source_files": "Sources/FluidAudio/**/*.swift",
  "ios": {
    "exclude_files": "Sources/FluidAudio/TextToSpeech/**/*",
    "frameworks": [
      "CoreML",
      "AVFoundation",
      "Accelerate",
      "UIKit"
    ]
  },
  "osx": {
    "vendored_frameworks": "Sources/FluidAudio/Frameworks/ESpeakNG.xcframework",
    "frameworks": [
      "CoreML",
      "AVFoundation",
      "Accelerate",
      "Cocoa"
    ]
  },
  "swift_versions": [
    "5.10"
  ],
  "pod_target_xcconfig": {
    "DEFINES_MODULE": "YES"
  },
  "swift_version": "5.10"
}
