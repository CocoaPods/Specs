{
  "name": "FluidAudio",
  "version": "0.6.1",
  "summary": "Speaker diarization, voice-activity-detection and transcription with CoreML",
  "description": "Fluid Audio is a Swift SDK for fully local, low-latency audio AI on Apple devices,\nwith inference offloaded to the Apple Neural Engine (ANE). The SDK includes\nstate-of-the-art speaker diarization, transcription, and voice activity detection\nvia open-source models that can be integrated with just a few lines of code.",
  "homepage": "https://github.com/FluidInference/FluidAudio",
  "license": {
    "type": "MIT",
    "file": "LICENSE"
  },
  "authors": {
    "FluidInference": "info@fluidinference.com"
  },
  "platforms": {
    "ios": "17.0",
    "osx": "14.0"
  },
  "source": {
    "git": "https://github.com/FluidInference/FluidAudio.git",
    "tag": "v0.6.1"
  },
  "source_files": "Sources/FluidAudio/**/*.swift",
  "swift_versions": [
    "5.10"
  ],
  "frameworks": [
    "CoreML",
    "AVFoundation",
    "Accelerate"
  ],
  "swift_version": "5.10"
}
